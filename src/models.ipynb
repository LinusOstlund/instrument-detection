{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "In this Notebook we'll train all models from the previously generated [features.csv](features.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('train.csv', index_col = 0)\n",
    "df_test = pd.read_csv('test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accordion', 'banjo', 'bass', 'cello', 'clarinet', 'cymbals', 'drums',\n",
       "       'flute', 'guitar', 'mallet_percussion', 'mandolin', 'organ', 'piano',\n",
       "       'saxophone', 'synthesizer', 'trombone', 'trumpet', 'ukulele', 'violin',\n",
       "       'voice', 'zcr_mean', 'zcr_std', 'sc_mean', 'sc_std', 'sb_mean',\n",
       "       'sb_std', 'sr_mean', 'sr_std', 'mfcc1_mean', 'mfcc1std', 'mfcc2_mean',\n",
       "       'mfcc2std', 'mfcc3_mean', 'mfcc3std', 'mfcc4_mean', 'mfcc4std',\n",
       "       'mfcc5_mean', 'mfcc5std', 'mfcc6_mean', 'mfcc6std', 'mfcc7_mean',\n",
       "       'mfcc7std', 'mfcc8_mean', 'mfcc8std', 'mfcc9_mean', 'mfcc9std',\n",
       "       'mfcc10_mean', 'mfcc10std', 'mfcc11_mean', 'mfcc11std', 'mfcc12_mean',\n",
       "       'mfcc12std', 'mfcc13_mean', 'mfcc13std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accordion</th>\n",
       "      <th>banjo</th>\n",
       "      <th>bass</th>\n",
       "      <th>cello</th>\n",
       "      <th>clarinet</th>\n",
       "      <th>cymbals</th>\n",
       "      <th>drums</th>\n",
       "      <th>flute</th>\n",
       "      <th>guitar</th>\n",
       "      <th>mallet_percussion</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc9_mean</th>\n",
       "      <th>mfcc9std</th>\n",
       "      <th>mfcc10_mean</th>\n",
       "      <th>mfcc10std</th>\n",
       "      <th>mfcc11_mean</th>\n",
       "      <th>mfcc11std</th>\n",
       "      <th>mfcc12_mean</th>\n",
       "      <th>mfcc12std</th>\n",
       "      <th>mfcc13_mean</th>\n",
       "      <th>mfcc13std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000046_3840</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.17105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>166.07562</td>\n",
       "      <td>216.15845</td>\n",
       "      <td>158.76860</td>\n",
       "      <td>209.78517</td>\n",
       "      <td>151.586730</td>\n",
       "      <td>203.43971</td>\n",
       "      <td>144.20024</td>\n",
       "      <td>197.13676</td>\n",
       "      <td>136.57768</td>\n",
       "      <td>190.80775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000135_483840</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>765.03280</td>\n",
       "      <td>495.68510</td>\n",
       "      <td>590.32880</td>\n",
       "      <td>558.75824</td>\n",
       "      <td>425.313660</td>\n",
       "      <td>616.81950</td>\n",
       "      <td>274.80215</td>\n",
       "      <td>663.55350</td>\n",
       "      <td>142.18160</td>\n",
       "      <td>694.35410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000139_119040</th>\n",
       "      <td>0.84485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>214.49968</td>\n",
       "      <td>316.38672</td>\n",
       "      <td>198.65715</td>\n",
       "      <td>314.67343</td>\n",
       "      <td>186.793670</td>\n",
       "      <td>313.87470</td>\n",
       "      <td>177.73270</td>\n",
       "      <td>313.87650</td>\n",
       "      <td>170.00764</td>\n",
       "      <td>313.99084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000141_153600</th>\n",
       "      <td>0.83820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.17840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>146.75562</td>\n",
       "      <td>140.59268</td>\n",
       "      <td>130.84398</td>\n",
       "      <td>137.76826</td>\n",
       "      <td>116.143745</td>\n",
       "      <td>135.27222</td>\n",
       "      <td>102.52170</td>\n",
       "      <td>133.01720</td>\n",
       "      <td>89.94732</td>\n",
       "      <td>130.88220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000144_30720</th>\n",
       "      <td>0.16215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>172.74915</td>\n",
       "      <td>268.45245</td>\n",
       "      <td>166.11035</td>\n",
       "      <td>266.88522</td>\n",
       "      <td>159.133510</td>\n",
       "      <td>265.19022</td>\n",
       "      <td>151.69370</td>\n",
       "      <td>263.76523</td>\n",
       "      <td>143.99810</td>\n",
       "      <td>262.70773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               accordion  banjo  bass  cello  clarinet  cymbals  drums  flute  \\\n",
       "000046_3840          NaN    NaN   NaN    NaN   0.17105      NaN    NaN    0.0   \n",
       "000135_483840        NaN    NaN   NaN    NaN       NaN      NaN    NaN    NaN   \n",
       "000139_119040    0.84485    NaN   NaN    NaN       NaN      NaN    NaN    NaN   \n",
       "000141_153600    0.83820    NaN   NaN    NaN   0.17840      NaN    NaN    NaN   \n",
       "000144_30720     0.16215    NaN   NaN    NaN       NaN      NaN    NaN    NaN   \n",
       "\n",
       "               guitar  mallet_percussion  ...  mfcc9_mean   mfcc9std  \\\n",
       "000046_3840       NaN                NaN  ...   166.07562  216.15845   \n",
       "000135_483840     NaN                NaN  ...   765.03280  495.68510   \n",
       "000139_119040     NaN                NaN  ...   214.49968  316.38672   \n",
       "000141_153600     NaN                NaN  ...   146.75562  140.59268   \n",
       "000144_30720      NaN                NaN  ...   172.74915  268.45245   \n",
       "\n",
       "               mfcc10_mean  mfcc10std  mfcc11_mean  mfcc11std  mfcc12_mean  \\\n",
       "000046_3840      158.76860  209.78517   151.586730  203.43971    144.20024   \n",
       "000135_483840    590.32880  558.75824   425.313660  616.81950    274.80215   \n",
       "000139_119040    198.65715  314.67343   186.793670  313.87470    177.73270   \n",
       "000141_153600    130.84398  137.76826   116.143745  135.27222    102.52170   \n",
       "000144_30720     166.11035  266.88522   159.133510  265.19022    151.69370   \n",
       "\n",
       "               mfcc12std  mfcc13_mean  mfcc13std  \n",
       "000046_3840    197.13676    136.57768  190.80775  \n",
       "000135_483840  663.55350    142.18160  694.35410  \n",
       "000139_119040  313.87650    170.00764  313.99084  \n",
       "000141_153600  133.01720     89.94732  130.88220  \n",
       "000144_30720   263.76523    143.99810  262.70773  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "instruments = ['accordion', 'banjo', 'bass', 'cello', 'clarinet',\n",
    "       'cymbals', 'drums', 'flute', 'guitar', 'mallet_percussion', 'mandolin',\n",
    "       'organ', 'piano', 'saxophone', 'synthesizer', 'trombone', 'trumpet',\n",
    "       'ukulele', 'violin', 'voice']\n",
    "\n",
    "article_instruments = ['flute', 'guitar', 'organ', 'piano', 'trumpet', 'voice']\n",
    "\n",
    "features = ['zcr_mean', 'zcr_std', 'sc_mean',\n",
    "       'sc_std', 'sb_mean', 'sb_std', 'sr_mean', 'sr_std', 'mfcc1_mean',\n",
    "       'mfcc1std', 'mfcc2_mean', 'mfcc2std', 'mfcc3_mean', 'mfcc3std',\n",
    "       'mfcc4_mean', 'mfcc4std', 'mfcc5_mean', 'mfcc5std', 'mfcc6_mean',\n",
    "       'mfcc6std', 'mfcc7_mean', 'mfcc7std', 'mfcc8_mean', 'mfcc8std',\n",
    "       'mfcc9_mean', 'mfcc9std', 'mfcc10_mean', 'mfcc10std', 'mfcc11_mean',\n",
    "       'mfcc11std', 'mfcc12_mean', 'mfcc12std', 'mfcc13_mean', 'mfcc13std']\n",
    "\n",
    "article_features = ['zcr_mean', 'sc_mean', 'sb_mean', 'sr_mean', 'mfcc1_mean',\n",
    "       'mfcc2_mean', 'mfcc3_mean', 'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean',\n",
    "       'mfcc7_mean', 'mfcc8_mean', 'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean',\n",
    "       'mfcc12_mean', 'mfcc13_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new cell to make switching between article features and full OPENMIC dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = article_features\n",
    "INSTRUMENTS = article_instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000046_3840      0.0\n",
       "000135_483840    NaN\n",
       "000139_119040    NaN\n",
       "000141_153600    NaN\n",
       "000144_30720     NaN\n",
       "Name: flute, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['flute'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flute': 0.0,\n",
       " 'guitar': nan,\n",
       " 'organ': nan,\n",
       " 'piano': nan,\n",
       " 'trumpet': 0.0,\n",
       " 'voice': nan}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trial = {}\n",
    "\n",
    "for index, row in df_train[INSTRUMENTS].iterrows():\n",
    "        #print(\"Frame: \\n\", row)\n",
    "        #print(\"Item: \\n\", index)\n",
    "        for instrument, observation in row.items():\n",
    "            y_trial[instrument] = observation\n",
    "        break\n",
    "y_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000504_203520    True\n",
       "000606_15360     True\n",
       "000725_445440    True\n",
       "001658_65280     True\n",
       "001703_130560    True\n",
       "Name: banjo, dtype: bool"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detta borde ju gÃ¥ \n",
    "df_train[df_train['banjo'] >= 0.5].notna()['banjo'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NedanstÃ¥ende celler fungerar, men rÃ¤knar med NaN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.array(df_train[FEATURES])\n",
    "# TODO: forloop \n",
    "# fungerar, men tar den bort NaN?\n",
    "y_train = {}\n",
    "for instrument in INSTRUMENTS:\n",
    "            y_train[instrument] = np.array(df_train[instrument] >= 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(df_test[FEATURES])\n",
    "# TODO: forloop \n",
    "# fungerar, men tar den bort NaN?\n",
    "y_test = {}\n",
    "for instrument in INSTRUMENTS:\n",
    "            y_test[instrument] = np.array(df_test[instrument] >= 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FÃ¶rsÃ¶ker lÃ¶sa problemet hÃ¤r :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flute 472\n",
      "guitar 852\n",
      "organ 482\n",
      "piano 885\n",
      "trumpet 828\n",
      "voice 764\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(df_train[FEATURES])\n",
    "# TODO: forloop \n",
    "y_train = {}\n",
    "for instrument in INSTRUMENTS:\n",
    "    y_train[instrument] = np.array(df_train[df_train[instrument] >= 0.5].notna()[instrument])\n",
    "\n",
    "for instrument in INSTRUMENTS:\n",
    "    print(instrument, len(y_train[instrument]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flute 175\n",
      "guitar 286\n",
      "organ 121\n",
      "piano 285\n",
      "trumpet 318\n",
      "voice 224\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(df_test[FEATURES])\n",
    "# TODO: forloop \n",
    "y_test = {}\n",
    "for instrument in INSTRUMENTS:\n",
    "    y_test[instrument] = np.array(df_test[df_test[instrument] >= 0.5].notna()[instrument])\n",
    "\n",
    "for instrument in INSTRUMENTS:\n",
    "    print(instrument, len(y_test[instrument]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training \n",
    "\n",
    "One main difference between the OpenMIC datset and IRMAS, is that OpenMIC has multilabel problemsn many cases. (A song can have multiple instrument classes assigned to it). In order to handle this we use train one binary classifier for each instrument. It's a naive approach and may be improved, but as beginning ML practioneers, it gives us some results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "instrument_dict = {\n",
    "    'flute': None,\n",
    "    'guitar': None,\n",
    "    'organ': None,\n",
    "    'piano': None,\n",
    "    'trumpet': None,\n",
    "    'voice': None\n",
    "}\n",
    "\n",
    "confusion_matrices = {\n",
    "    'LogisticRegression': instrument_dict.copy(),\n",
    "    'DecisionTree': instrument_dict.copy(),\n",
    "    'LGBM': instrument_dict.copy(),\n",
    "    'XGBoost': instrument_dict.copy(),\n",
    "    'RandomForestClassifier': instrument_dict.copy(),\n",
    "    'SVM': instrument_dict.copy()\n",
    "\n",
    "}\n",
    "\n",
    "def print_classification_report(y_true, y_pred, instrument, model):\n",
    "    \"\"\"\n",
    "    Helper method to print classification report and store confusion matrix\n",
    "    \"\"\"\n",
    "    print(\"##############################################\")\n",
    "    print(\"Classification report for {}\".format(instrument))\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(report)\n",
    "    confusion_matrices[model][instrument] = confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am storing all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14915, 472]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [93], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m lr \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instrument \u001b[38;5;129;01min\u001b[39;00m article_instruments:\n\u001b[0;32m----> 6\u001b[0m     clf \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43minstrument\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      8\u001b[0m     print_classification_report(y_true\u001b[38;5;241m=\u001b[39my_test[instrument], y_pred\u001b[38;5;241m=\u001b[39my_pred, instrument\u001b[38;5;241m=\u001b[39minstrument, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogisticRegression\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1138\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[0;32m-> 1138\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1139\u001b[0m     X,\n\u001b[1;32m   1140\u001b[0m     y,\n\u001b[1;32m   1141\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1142\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[1;32m   1143\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1144\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1145\u001b[0m )\n\u001b[1;32m   1146\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1092\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m-> 1092\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14915, 472]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = {}\n",
    "\n",
    "for instrument in article_instruments:\n",
    "    clf = LogisticRegression(random_state=0, max_iter=50).fit(X_train, y_train[instrument])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print_classification_report(y_true=y_test[instrument], y_pred=y_pred, instrument=instrument, model='LogisticRegression')\n",
    "    lr[instrument] = clf\n",
    "\n",
    "clfs[\"Logistic Regression\"] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14915, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "len(y_train[\"piano\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=472 does not match number of samples=14915",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [94], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m dct \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instrument \u001b[38;5;129;01min\u001b[39;00m article_instruments:\n\u001b[0;32m----> 6\u001b[0m     clf \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDecisionTreeClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43minstrument\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      8\u001b[0m     print_classification_report(y_true\u001b[38;5;241m=\u001b[39my_test[instrument], y_pred\u001b[38;5;241m=\u001b[39my_pred, instrument\u001b[38;5;241m=\u001b[39minstrument, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecisionTree\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    970\u001b[0m         X,\n\u001b[1;32m    971\u001b[0m         y,\n\u001b[1;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py:366\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    358\u001b[0m check_scalar(\n\u001b[1;32m    359\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    360\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmin_impurity_decrease\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m     target_type\u001b[39m=\u001b[39mnumbers\u001b[39m.\u001b[39mReal,\n\u001b[1;32m    362\u001b[0m     min_val\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m,\n\u001b[1;32m    363\u001b[0m )\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y) \u001b[39m!=\u001b[39m n_samples:\n\u001b[0;32m--> 366\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    367\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of labels=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m does not match number of samples=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(y), n_samples)\n\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    371\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels=472 does not match number of samples=14915"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dct = {}\n",
    "\n",
    "for instrument in INSTRUMENTS:\n",
    "    clf = tree.DecisionTreeClassifier().fit(X_train, y_train[instrument])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print_classification_report(y_true=y_test[instrument], y_pred=y_pred, instrument=instrument, model='DecisionTree')\n",
    "    dct[instrument] = clf\n",
    "    \n",
    "clfs[\"Decision Tree\"] = dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(df_test[article_features])\n",
    "y_test = np.array(df_test[\"drums\"] >= 0.5)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [71], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(confusion_matrices):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, instrument \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(model):\n\u001b[0;32m---> 13\u001b[0m         \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstrument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/seaborn/matrix.py:543\u001b[0m, in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \n\u001b[1;32m    367\u001b[0m \u001b[39mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[39m    ...     ax = sns.heatmap(corr, mask=mask, vmax=.3, square=True)\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[39m# Initialize the plotter object\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m plotter \u001b[39m=\u001b[39m _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[1;32m    544\u001b[0m                       annot_kws, cbar, cbar_kws, xticklabels,\n\u001b[1;32m    545\u001b[0m                       yticklabels, mask)\n\u001b[1;32m    547\u001b[0m \u001b[39m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[1;32m    548\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mlinewidths\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m linewidths\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/seaborn/matrix.py:110\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     plot_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(data)\n\u001b[0;32m--> 110\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(plot_data)\n\u001b[1;32m    112\u001b[0m \u001b[39m# Validate the mask and convert to DataFrame\u001b[39;00m\n\u001b[1;32m    113\u001b[0m mask \u001b[39m=\u001b[39m _matrix_mask(data, mask)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    711\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    712\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    713\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    719\u001b[0m         )\n\u001b[1;32m    720\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    722\u001b[0m             data,\n\u001b[1;32m    723\u001b[0m             index,\n\u001b[1;32m    724\u001b[0m             columns,\n\u001b[1;32m    725\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    726\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    727\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    728\u001b[0m         )\n\u001b[1;32m    730\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:330\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    325\u001b[0m         values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    327\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     \u001b[39m# by definition an array here\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[39m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m     values \u001b[39m=\u001b[39m _prep_ndarraylike(values, copy\u001b[39m=\u001b[39;49mcopy_on_sanitize)\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dtype_equal(values\u001b[39m.\u001b[39mdtype, dtype):\n\u001b[1;32m    333\u001b[0m     \u001b[39m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     rcf \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m (is_integer_dtype(dtype) \u001b[39mand\u001b[39;00m values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:584\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    582\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m))\n\u001b[1;32m    583\u001b[0m \u001b[39melif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 584\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMust pass 2-d input. shape=\u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    586\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=()"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 48 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "#cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(6, 8, figsize=(15, 5))\n",
    "\n",
    "\n",
    "for i, model in enumerate(confusion_matrices):\n",
    "    for j, instrument in enumerate(model):\n",
    "        sns.heatmap(instrument, ax=axes[i, j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 150\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "clf.predict(X[:2, :])\n",
    "\n",
    "clf.predict_proba(X[:2, :])\n",
    "\n",
    "\n",
    "clf.score(X, y)\n",
    "print(len(X), len(y))\n",
    "print(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
