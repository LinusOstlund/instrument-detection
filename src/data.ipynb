{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File structuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up the `DATA_ROOT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '../data/openmic-2018/'\n",
    "\n",
    "if not os.path.exists(DATA_ROOT):\n",
    "    raise ValueError('Did you forget to set `DATA_ROOT`?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `OPENMIC` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "OPENMIC = np.load(os.path.join(DATA_ROOT, 'openmic-2018.npz'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the dataset is described in detail on the [OPENMIC's Official Github](https://github.com/cosmir/openmic-2018/blob/master/examples/modeling-baseline.ipynb). It contains VGGish features, which are to be excluded, as we want to replicate the analysis of [Predominant Musical Instrument Classification based on Spectral Features\n",
    "](https://arxiv.org/abs/1912.02606) (PMICSF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y_true, Y_mask, sample_key = OPENMIC['X'], OPENMIC['Y_true'], OPENMIC['Y_mask'], OPENMIC['sample_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "The goal is to replicate the approach of [PMICSF](https://arxiv.org/abs/1912.02606). The features used in the article are:\n",
    "\n",
    "* **Zero Crossing Rate** (ZCR):  indicates the rate at which the signal crosses zero.\n",
    "* **Spectral Centroid** (SC): a metric that indicate the center of mass of the spectrum being located. It is *\"the ratio of the frequency weighted magnitude spectrum with unweighted magnitude spectrum\"*\n",
    "* **Spectral Bandwidth** (SB): gives the weighted average of the frequency signal by its spectrum.\n",
    "* **Spectral roll-off** (SR):  the frequency under which a certain proportion of the overall spectral energy belongs to\n",
    "* **MFCC**: the meaon of the first 13 MFCC features.\n",
    "\n",
    "We intend to  calculate these features for the `OPENMIC` dataset, and store them in a Panda's Dataframe ordered by sample key. The sample keys are available in the `sample_key` list produced in the code block above.\n",
    "\n",
    "\n",
    "> **Question**: what did they use on Librosa? Same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From PMICSF, page 3:\n",
    "\n",
    ">  The audio spectrum is analyzed by extracting MFCCs based on the default inputs of hopSize (hop length between frames) and frame size. The default parameters for sampling rate is 44.1 kHz, **hopSize of 512** and **frame size of 1024** in Essentia\n",
    "\n",
    "For convinience, and according to [Presets](https://librosa.org/blog/2019/07/17/resample-on-load/), we set the default parameters of Librosa to match those values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first define the default values to match PMICSF\n",
    "# TODO: why import it as _librosa?\n",
    "from presets import Preset\n",
    "import librosa as _librosa\n",
    "librosa = Preset(_librosa)\n",
    "librosa['n_fft'] = 2048\n",
    "librosa['win_length'] = 1024\n",
    "librosa['hop_length'] = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find all audio files in the dataset, Librosa's util function [find_files](https://librosa.org/doc/main/generated/librosa.util.find_files.html) was used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>sample_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/workspaces/instrument-detection/data/openmic-...</td>\n",
       "      <td>000046_3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/workspaces/instrument-detection/data/openmic-...</td>\n",
       "      <td>000135_483840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/workspaces/instrument-detection/data/openmic-...</td>\n",
       "      <td>000139_119040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/workspaces/instrument-detection/data/openmic-...</td>\n",
       "      <td>000141_153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/workspaces/instrument-detection/data/openmic-...</td>\n",
       "      <td>000144_30720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>/workspaces/instrument-detection/data/openmic-...</td>\n",
       "      <td>155294_184320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>/workspaces/instrument-detection/data/openmic-...</td>\n",
       "      <td>155295_76800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>/workspaces/instrument-detection/data/openmic-...</td>\n",
       "      <td>155307_211200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>/workspaces/instrument-detection/data/openmic-...</td>\n",
       "      <td>155310_372480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>/workspaces/instrument-detection/data/openmic-...</td>\n",
       "      <td>155311_453120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               file_path     sample_key\n",
       "0      /workspaces/instrument-detection/data/openmic-...    000046_3840\n",
       "1      /workspaces/instrument-detection/data/openmic-...  000135_483840\n",
       "2      /workspaces/instrument-detection/data/openmic-...  000139_119040\n",
       "3      /workspaces/instrument-detection/data/openmic-...  000141_153600\n",
       "4      /workspaces/instrument-detection/data/openmic-...   000144_30720\n",
       "...                                                  ...            ...\n",
       "19995  /workspaces/instrument-detection/data/openmic-...  155294_184320\n",
       "19996  /workspaces/instrument-detection/data/openmic-...   155295_76800\n",
       "19997  /workspaces/instrument-detection/data/openmic-...  155307_211200\n",
       "19998  /workspaces/instrument-detection/data/openmic-...  155310_372480\n",
       "19999  /workspaces/instrument-detection/data/openmic-...  155311_453120\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa as lr\n",
    "import pandas as pd\n",
    "\n",
    "file_paths = lr.util.find_files(DATA_ROOT + \"audio\", ext=\"ogg\")\n",
    "index = pd.DataFrame({\"file_path\": file_paths, \"sample_key\": sample_key})\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    /workspaces/instrument-detection/data/openmic-...\n",
       "1    /workspaces/instrument-detection/data/openmic-...\n",
       "2    /workspaces/instrument-detection/data/openmic-...\n",
       "3    /workspaces/instrument-detection/data/openmic-...\n",
       "4    /workspaces/instrument-detection/data/openmic-...\n",
       "Name: file_path, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index['file_path'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to preprocess all files and extract all features. For efficiancy, we used Spotify's [Pedalboard](https://github.com/spotify/pedalboard) for loading audio and Librosas Feature package for feature extraction. Below is what packages we used:\n",
    "\n",
    "* ZCR: [librosa.feature.zero_crossing_rate](https://librosa.org/doc/main/generated/librosa.feature.zero_crossing_rate.html)\n",
    "* SC: [librosa.feature.spectral_centroid](https://librosa.org/doc/main/generated/librosa.feature.spectral_centroid.html)\n",
    "* SB: [librosa.feature.spectral_bandwidth](https://librosa.org/doc/main/generated/librosa.feature.spectral_bandwidth.html)\n",
    "* SR: [librosa.feature.spectral_rolloff](https://librosa.org/doc/main/generated/librosa.feature.spectral_rolloff.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article also extracts the mean of the first 13 MFCC features with Librosa:\n",
    "\n",
    "> We extracted the first 13 MFCC features using Librosa/Essentia. For each audio clip, we obtained 259 × 13 matrix features. **We took the mean of all the columns to get the condensed feature** providing us with 1 × 13 feature vector, along with five other features as mentioned above. We labeled each vector with the instrument class using scikit- learn’s ‘labelencoder’ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import ycor\n",
    "import pedalboard as pb\n",
    "import librosa as lr\n",
    "\n",
    "\n",
    "def preprocess(index):\n",
    "    \"\"\"\n",
    "    Preprocess audio and extract features according to PMICSF\n",
    "    Input: an audiofile\n",
    "    Returns: a dictionary with zcrs, scs, mfccs\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    with pb.io.AudioFile(index[0]) as f:\n",
    "        # TODO so some files have varying SR, which could be problematic\n",
    "        #assert f.samplerate == 44100, f\"Sample rate is not 44.1khz for {file}!\"\n",
    "        # TODO count _one_ spectogram and then use as input to all features\n",
    "        y = f.read(f.frames)\n",
    "        y = y.mean(axis=0)  # mono\n",
    "        # To speed up calculation, calculate one spectogram\n",
    "        # TODO is this right, and does the standard values as defined above really hold?\n",
    "        S = np.abs(librosa.stft(y))**2\n",
    "        zcrs = librosa.feature.zero_crossing_rate(y=y)\n",
    "        features[\"sample_key\"] = index[1]\n",
    "        features[\"zcr_mean\"] = zcrs.mean()\n",
    "        features[\"zcr_std\"] = zcrs.std()\n",
    "        scs = librosa.feature.spectral_centroid(S=S)\n",
    "        features[\"sc_mean\"] = scs.mean()\n",
    "        features[\"sc_std\"] = scs.std()\n",
    "        sbs = librosa.feature.spectral_bandwidth(S=S)\n",
    "        features[\"sb_mean\"] = sbs.mean()\n",
    "        features[\"sb_std\"] = sbs.std()\n",
    "        srs = librosa.feature.spectral_rolloff(S=S)\n",
    "        features[\"sr_mean\"] = sbs.mean()\n",
    "        features[\"sr_std\"] = sbs.std()\n",
    "        mfccs = librosa.feature.mfcc(S=librosa.power_to_db(S), n_mfcc=13)\n",
    "        for i, mfcc in enumerate(mfccs):\n",
    "            features['mfcc' + str(i+1) + '_mean'] = mfcc.mean()\n",
    "            features['mfcc' + str(i+1) + 'std'] = mfcc.std()\n",
    "\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The audio files were preprocessed in parallell, using Python's [multiprocess](https://docs.python.org/3/library/multiprocessing.html) package.\n",
    "\n",
    "> **NOTE:** if using the enclosed `.devcontainer`, make sure to adjust the RAM and available cores in your Docker settings. Not doing so will render the kernel to crash! We used 4gb ram and 6 cores on a MacBook Air M1, leading to a calculation time of roughly 10 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/workspaces/instrument-detection/data/openmic-2018/audio/000/000046_3840.ogg',\n",
       "  '000046_3840'],\n",
       " ['/workspaces/instrument-detection/data/openmic-2018/audio/000/000135_483840.ogg',\n",
       "  '000135_483840'],\n",
       " ['/workspaces/instrument-detection/data/openmic-2018/audio/000/000139_119040.ogg',\n",
       "  '000139_119040'],\n",
       " ['/workspaces/instrument-detection/data/openmic-2018/audio/000/000141_153600.ogg',\n",
       "  '000141_153600'],\n",
       " ['/workspaces/instrument-detection/data/openmic-2018/audio/000/000144_30720.ogg',\n",
       "  '000144_30720']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sandbox\n",
    "\n",
    "ttt = index.values.tolist()\n",
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [17:06<00:00, 19.48it/s]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_key</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>sc_mean</th>\n",
       "      <th>sc_std</th>\n",
       "      <th>sb_mean</th>\n",
       "      <th>sb_std</th>\n",
       "      <th>sr_mean</th>\n",
       "      <th>sr_std</th>\n",
       "      <th>mfcc1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc9_mean</th>\n",
       "      <th>mfcc9std</th>\n",
       "      <th>mfcc10_mean</th>\n",
       "      <th>mfcc10std</th>\n",
       "      <th>mfcc11_mean</th>\n",
       "      <th>mfcc11std</th>\n",
       "      <th>mfcc12_mean</th>\n",
       "      <th>mfcc12std</th>\n",
       "      <th>mfcc13_mean</th>\n",
       "      <th>mfcc13std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000046_3840</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>0.021923</td>\n",
       "      <td>296.517136</td>\n",
       "      <td>133.109808</td>\n",
       "      <td>288.159666</td>\n",
       "      <td>267.139540</td>\n",
       "      <td>288.159666</td>\n",
       "      <td>267.139540</td>\n",
       "      <td>-978.598022</td>\n",
       "      <td>...</td>\n",
       "      <td>36.752838</td>\n",
       "      <td>18.461390</td>\n",
       "      <td>21.056427</td>\n",
       "      <td>14.100028</td>\n",
       "      <td>16.246675</td>\n",
       "      <td>12.125834</td>\n",
       "      <td>23.335825</td>\n",
       "      <td>16.301609</td>\n",
       "      <td>14.897064</td>\n",
       "      <td>12.292964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000135_483840</td>\n",
       "      <td>0.052411</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>478.192757</td>\n",
       "      <td>141.199973</td>\n",
       "      <td>409.844515</td>\n",
       "      <td>135.532246</td>\n",
       "      <td>409.844515</td>\n",
       "      <td>135.532246</td>\n",
       "      <td>-413.563721</td>\n",
       "      <td>...</td>\n",
       "      <td>6.231468</td>\n",
       "      <td>14.745573</td>\n",
       "      <td>17.053007</td>\n",
       "      <td>12.037521</td>\n",
       "      <td>-11.894317</td>\n",
       "      <td>11.358349</td>\n",
       "      <td>5.294181</td>\n",
       "      <td>12.435369</td>\n",
       "      <td>2.507157</td>\n",
       "      <td>12.328708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000139_119040</td>\n",
       "      <td>0.081234</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>604.505859</td>\n",
       "      <td>189.731508</td>\n",
       "      <td>719.222449</td>\n",
       "      <td>139.070343</td>\n",
       "      <td>719.222449</td>\n",
       "      <td>139.070343</td>\n",
       "      <td>-544.543701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072678</td>\n",
       "      <td>13.965829</td>\n",
       "      <td>-26.966000</td>\n",
       "      <td>14.030764</td>\n",
       "      <td>26.628426</td>\n",
       "      <td>13.969789</td>\n",
       "      <td>17.684668</td>\n",
       "      <td>10.871439</td>\n",
       "      <td>-17.259043</td>\n",
       "      <td>12.796794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000141_153600</td>\n",
       "      <td>0.053718</td>\n",
       "      <td>0.013248</td>\n",
       "      <td>462.825122</td>\n",
       "      <td>153.244140</td>\n",
       "      <td>391.783679</td>\n",
       "      <td>84.894649</td>\n",
       "      <td>391.783679</td>\n",
       "      <td>84.894649</td>\n",
       "      <td>-934.030762</td>\n",
       "      <td>...</td>\n",
       "      <td>9.737517</td>\n",
       "      <td>12.798279</td>\n",
       "      <td>25.201883</td>\n",
       "      <td>11.753377</td>\n",
       "      <td>35.146244</td>\n",
       "      <td>11.763553</td>\n",
       "      <td>28.466101</td>\n",
       "      <td>11.159425</td>\n",
       "      <td>9.925189</td>\n",
       "      <td>10.857844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000144_30720</td>\n",
       "      <td>0.082449</td>\n",
       "      <td>0.034076</td>\n",
       "      <td>601.706717</td>\n",
       "      <td>329.074617</td>\n",
       "      <td>766.763811</td>\n",
       "      <td>375.408621</td>\n",
       "      <td>766.763811</td>\n",
       "      <td>375.408621</td>\n",
       "      <td>-561.763611</td>\n",
       "      <td>...</td>\n",
       "      <td>27.277163</td>\n",
       "      <td>19.787683</td>\n",
       "      <td>13.598028</td>\n",
       "      <td>16.042135</td>\n",
       "      <td>14.319709</td>\n",
       "      <td>16.555758</td>\n",
       "      <td>27.292217</td>\n",
       "      <td>15.994335</td>\n",
       "      <td>0.721995</td>\n",
       "      <td>16.865313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>155294_184320</td>\n",
       "      <td>0.050435</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>508.286842</td>\n",
       "      <td>94.249039</td>\n",
       "      <td>266.331118</td>\n",
       "      <td>63.090107</td>\n",
       "      <td>266.331118</td>\n",
       "      <td>63.090107</td>\n",
       "      <td>-978.444946</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.920152</td>\n",
       "      <td>10.829905</td>\n",
       "      <td>-14.391589</td>\n",
       "      <td>9.820566</td>\n",
       "      <td>-8.987197</td>\n",
       "      <td>9.933827</td>\n",
       "      <td>-2.683615</td>\n",
       "      <td>8.903602</td>\n",
       "      <td>-1.517069</td>\n",
       "      <td>9.117269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>155295_76800</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>61.216410</td>\n",
       "      <td>42.815086</td>\n",
       "      <td>101.288169</td>\n",
       "      <td>53.390921</td>\n",
       "      <td>101.288169</td>\n",
       "      <td>53.390921</td>\n",
       "      <td>-1092.291382</td>\n",
       "      <td>...</td>\n",
       "      <td>41.367481</td>\n",
       "      <td>9.498998</td>\n",
       "      <td>33.264076</td>\n",
       "      <td>7.879162</td>\n",
       "      <td>28.860458</td>\n",
       "      <td>6.616966</td>\n",
       "      <td>24.709829</td>\n",
       "      <td>6.231831</td>\n",
       "      <td>20.218401</td>\n",
       "      <td>5.848857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>155307_211200</td>\n",
       "      <td>0.065545</td>\n",
       "      <td>0.022368</td>\n",
       "      <td>450.432458</td>\n",
       "      <td>192.751011</td>\n",
       "      <td>665.939788</td>\n",
       "      <td>285.751704</td>\n",
       "      <td>665.939788</td>\n",
       "      <td>285.751704</td>\n",
       "      <td>-625.574707</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175638</td>\n",
       "      <td>16.541275</td>\n",
       "      <td>29.078180</td>\n",
       "      <td>17.536085</td>\n",
       "      <td>-2.689997</td>\n",
       "      <td>16.350401</td>\n",
       "      <td>0.299629</td>\n",
       "      <td>17.147369</td>\n",
       "      <td>9.396278</td>\n",
       "      <td>15.461529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>155310_372480</td>\n",
       "      <td>0.042145</td>\n",
       "      <td>0.015084</td>\n",
       "      <td>332.139261</td>\n",
       "      <td>146.760990</td>\n",
       "      <td>409.563611</td>\n",
       "      <td>169.775745</td>\n",
       "      <td>409.563611</td>\n",
       "      <td>169.775745</td>\n",
       "      <td>-786.657532</td>\n",
       "      <td>...</td>\n",
       "      <td>35.033508</td>\n",
       "      <td>19.646029</td>\n",
       "      <td>26.835651</td>\n",
       "      <td>18.322279</td>\n",
       "      <td>-27.157253</td>\n",
       "      <td>22.870502</td>\n",
       "      <td>-6.835197</td>\n",
       "      <td>24.779594</td>\n",
       "      <td>17.680960</td>\n",
       "      <td>16.964596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>155311_453120</td>\n",
       "      <td>0.039820</td>\n",
       "      <td>0.016151</td>\n",
       "      <td>300.841059</td>\n",
       "      <td>117.395470</td>\n",
       "      <td>388.035180</td>\n",
       "      <td>205.422401</td>\n",
       "      <td>388.035180</td>\n",
       "      <td>205.422401</td>\n",
       "      <td>-717.562866</td>\n",
       "      <td>...</td>\n",
       "      <td>16.477861</td>\n",
       "      <td>13.324247</td>\n",
       "      <td>27.590900</td>\n",
       "      <td>13.692442</td>\n",
       "      <td>5.828809</td>\n",
       "      <td>12.366935</td>\n",
       "      <td>8.889007</td>\n",
       "      <td>10.795358</td>\n",
       "      <td>19.552170</td>\n",
       "      <td>11.692119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sample_key  zcr_mean   zcr_std     sc_mean      sc_std     sb_mean  \\\n",
       "0        000046_3840  0.036367  0.021923  296.517136  133.109808  288.159666   \n",
       "1      000135_483840  0.052411  0.013491  478.192757  141.199973  409.844515   \n",
       "2      000139_119040  0.081234  0.014925  604.505859  189.731508  719.222449   \n",
       "3      000141_153600  0.053718  0.013248  462.825122  153.244140  391.783679   \n",
       "4       000144_30720  0.082449  0.034076  601.706717  329.074617  766.763811   \n",
       "...              ...       ...       ...         ...         ...         ...   \n",
       "19995  155294_184320  0.050435  0.009352  508.286842   94.249039  266.331118   \n",
       "19996   155295_76800  0.009752  0.004809   61.216410   42.815086  101.288169   \n",
       "19997  155307_211200  0.065545  0.022368  450.432458  192.751011  665.939788   \n",
       "19998  155310_372480  0.042145  0.015084  332.139261  146.760990  409.563611   \n",
       "19999  155311_453120  0.039820  0.016151  300.841059  117.395470  388.035180   \n",
       "\n",
       "           sb_std     sr_mean      sr_std   mfcc1_mean  ...  mfcc9_mean  \\\n",
       "0      267.139540  288.159666  267.139540  -978.598022  ...   36.752838   \n",
       "1      135.532246  409.844515  135.532246  -413.563721  ...    6.231468   \n",
       "2      139.070343  719.222449  139.070343  -544.543701  ...   -0.072678   \n",
       "3       84.894649  391.783679   84.894649  -934.030762  ...    9.737517   \n",
       "4      375.408621  766.763811  375.408621  -561.763611  ...   27.277163   \n",
       "...           ...         ...         ...          ...  ...         ...   \n",
       "19995   63.090107  266.331118   63.090107  -978.444946  ...  -11.920152   \n",
       "19996   53.390921  101.288169   53.390921 -1092.291382  ...   41.367481   \n",
       "19997  285.751704  665.939788  285.751704  -625.574707  ...    1.175638   \n",
       "19998  169.775745  409.563611  169.775745  -786.657532  ...   35.033508   \n",
       "19999  205.422401  388.035180  205.422401  -717.562866  ...   16.477861   \n",
       "\n",
       "        mfcc9std  mfcc10_mean  mfcc10std  mfcc11_mean  mfcc11std  mfcc12_mean  \\\n",
       "0      18.461390    21.056427  14.100028    16.246675  12.125834    23.335825   \n",
       "1      14.745573    17.053007  12.037521   -11.894317  11.358349     5.294181   \n",
       "2      13.965829   -26.966000  14.030764    26.628426  13.969789    17.684668   \n",
       "3      12.798279    25.201883  11.753377    35.146244  11.763553    28.466101   \n",
       "4      19.787683    13.598028  16.042135    14.319709  16.555758    27.292217   \n",
       "...          ...          ...        ...          ...        ...          ...   \n",
       "19995  10.829905   -14.391589   9.820566    -8.987197   9.933827    -2.683615   \n",
       "19996   9.498998    33.264076   7.879162    28.860458   6.616966    24.709829   \n",
       "19997  16.541275    29.078180  17.536085    -2.689997  16.350401     0.299629   \n",
       "19998  19.646029    26.835651  18.322279   -27.157253  22.870502    -6.835197   \n",
       "19999  13.324247    27.590900  13.692442     5.828809  12.366935     8.889007   \n",
       "\n",
       "       mfcc12std  mfcc13_mean  mfcc13std  \n",
       "0      16.301609    14.897064  12.292964  \n",
       "1      12.435369     2.507157  12.328708  \n",
       "2      10.871439   -17.259043  12.796794  \n",
       "3      11.159425     9.925189  10.857844  \n",
       "4      15.994335     0.721995  16.865313  \n",
       "...          ...          ...        ...  \n",
       "19995   8.903602    -1.517069   9.117269  \n",
       "19996   6.231831    20.218401   5.848857  \n",
       "19997  17.147369     9.396278  15.461529  \n",
       "19998  24.779594    17.680960  16.964596  \n",
       "19999  10.795358    19.552170  11.692119  \n",
       "\n",
       "[20000 rows x 35 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from multiprocess import Pool\n",
    "if not os.path.exists('features'):\n",
    "    with Pool() as p:\n",
    "        # index.values.tolist() returns a list with [file_path, sample_key]\n",
    "        ys = list(tqdm(p.imap(preprocess, index.values.tolist()), total=len(index)))\n",
    "else:\n",
    "    ys = pd.DataFrame.from_csv('features.csv')\n",
    "pd.DataFrame(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we want to store the features in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ys).to_csv(path_or_buf='features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Labeling\n",
    "> **NOTERING**: Se även [test.ipynb](/src/test.ipynb)\n",
    "\n",
    "From PMICSF part C, *Classifier Training*\n",
    "\n",
    "> We labeled each vector with the instrument class using scikitlearn’s ‘labelencoder’ function\n",
    "\n",
    "> **Question**: not sure how they use [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n",
    "\n",
    "The team behind OPENMIC has made a good split of the data, and most of the following code is from their [tutorial on GitHub](https://github.com/cosmir/openmic-2018/blob/master/examples/modeling-baseline.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68362/2913080075.py:4: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  split_train = pd.read_csv(\n",
      "/tmp/ipykernel_68362/2913080075.py:7: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  split_test = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      000178_3840\n",
       "1     000308_61440\n",
       "2    000312_184320\n",
       "3    000319_145920\n",
       "4    000321_218880\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's split the data into the training and test set\n",
    "# We use squeeze=True here to return a single array for each, rather than a full DataFrame\n",
    "\n",
    "split_train = pd.read_csv(\n",
    "    os.path.join(DATA_ROOT, \"partitions/split01_train.csv\"), header=None, squeeze=True\n",
    ")\n",
    "split_test = pd.read_csv(\n",
    "    os.path.join(DATA_ROOT, \"partitions/split01_test.csv\"), header=None, squeeze=True\n",
    ")\n",
    "\n",
    "split_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 14915,  # Test: 5085\n"
     ]
    }
   ],
   "source": [
    "# How many train and test examples do we have?  About 75%/25%\n",
    "print(\"# Train: {},  # Test: {}\".format(len(split_train), len(split_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to set\n",
    "train_set = set(split_train)\n",
    "test_set = set(split_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These loops go through all sample keys, and save their row numbers\n",
    "# to either idx_train or idx_test\n",
    "#\n",
    "# This will be useful in the next step for slicing the array data\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(sample_key):\n",
    "    if n in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n in test_set:\n",
    "        idx_test.append(idx)\n",
    "    else:\n",
    "        # This should never happen, but better safe than sorry.\n",
    "        raise RuntimeError(\"Unknown sample key={}! Abort!\".format(sample_key[n]))\n",
    "\n",
    "# Finally, cast the idx_* arrays to numpy structures\n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From OPENMIC tutorial:\n",
    "\n",
    "> For convenience, we provide a simple JSON object that maps class indices to names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accordion': 0,\n",
       " 'banjo': 1,\n",
       " 'bass': 2,\n",
       " 'cello': 3,\n",
       " 'clarinet': 4,\n",
       " 'cymbals': 5,\n",
       " 'drums': 6,\n",
       " 'flute': 7,\n",
       " 'guitar': 8,\n",
       " 'mallet_percussion': 9,\n",
       " 'mandolin': 10,\n",
       " 'organ': 11,\n",
       " 'piano': 12,\n",
       " 'saxophone': 13,\n",
       " 'synthesizer': 14,\n",
       " 'trombone': 15,\n",
       " 'trumpet': 16,\n",
       " 'ukulele': 17,\n",
       " 'violin': 18,\n",
       " 'voice': 19}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(DATA_ROOT, 'class-map.json'), 'r') as f:\n",
    "    class_map = json.load(f)\n",
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = Y_mask[idx_train]\n",
    "data_test = Y_mask[idx_train]\n",
    "sample_key_train = sample_key[idx_train]  # numpy.ndarray\n",
    "sample_key_test = sample_key[idx_test]\n",
    "\n",
    "type(sample_key_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we use the split indices to partition the features, labels, and masks\n",
    "X_train = X[idx_train]\n",
    "X_test = X[idx_test]\n",
    "\n",
    "Y_true_train = Y_true[idx_train]\n",
    "Y_true_test = Y_true[idx_test]\n",
    "\n",
    "Y_mask_train = Y_mask[idx_train]\n",
    "Y_mask_test = Y_mask[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe_with_labels(indices, class_map, Y_mask):\n",
    "    \"\"\"\n",
    "    A method for creating a pd.df with each label in Y_mask and instrument in class_map\n",
    "    Requires sorting of indices first (idx_train and idx_test) as explained in OPENMIC2018 tutorial\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for i in indices:\n",
    "        tmp_dict = {}\n",
    "        for instr, pred in zip(class_map, Y_mask[i]):\n",
    "            tmp_dict[instr] = pred\n",
    "        data[sample_key[i]] = tmp_dict\n",
    "\n",
    "    return pd.DataFrame.from_dict(data, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the util function above, we create a big table with all the labels, as predicted by the OPENMIC team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accordion</th>\n",
       "      <th>banjo</th>\n",
       "      <th>bass</th>\n",
       "      <th>cello</th>\n",
       "      <th>clarinet</th>\n",
       "      <th>cymbals</th>\n",
       "      <th>drums</th>\n",
       "      <th>flute</th>\n",
       "      <th>guitar</th>\n",
       "      <th>mallet_percussion</th>\n",
       "      <th>mandolin</th>\n",
       "      <th>organ</th>\n",
       "      <th>piano</th>\n",
       "      <th>saxophone</th>\n",
       "      <th>synthesizer</th>\n",
       "      <th>trombone</th>\n",
       "      <th>trumpet</th>\n",
       "      <th>ukulele</th>\n",
       "      <th>violin</th>\n",
       "      <th>voice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000178_3840</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000308_61440</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000312_184320</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000319_145920</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000321_218880</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accordion  banjo   bass  cello  clarinet  cymbals  drums  \\\n",
       "000178_3840        False  False  False  False     False    False  False   \n",
       "000308_61440       False  False   True  False     False    False  False   \n",
       "000312_184320      False  False  False  False     False    False  False   \n",
       "000319_145920      False  False   True  False     False    False  False   \n",
       "000321_218880      False  False   True  False     False    False  False   \n",
       "\n",
       "               flute  guitar  mallet_percussion  mandolin  organ  piano  \\\n",
       "000178_3840    False   False              False     False  False  False   \n",
       "000308_61440   False   False              False     False   True  False   \n",
       "000312_184320  False   False              False     False  False  False   \n",
       "000319_145920  False   False              False     False  False  False   \n",
       "000321_218880  False   False              False     False  False  False   \n",
       "\n",
       "               saxophone  synthesizer  trombone  trumpet  ukulele  violin  \\\n",
       "000178_3840        False        False     False    False    False   False   \n",
       "000308_61440       False        False     False    False    False   False   \n",
       "000312_184320      False        False      True    False    False   False   \n",
       "000319_145920      False        False     False    False    False   False   \n",
       "000321_218880      False         True     False    False    False   False   \n",
       "\n",
       "               voice  \n",
       "000178_3840     True  \n",
       "000308_61440   False  \n",
       "000312_184320  False  \n",
       "000319_145920  False  \n",
       "000321_218880  False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up dataframes with sample key and correct label\n",
    "df_train = generate_dataframe_with_labels(idx_train, class_map, Y_mask)\n",
    "df_test = generate_dataframe_with_labels(idx_test, class_map, Y_mask)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we perhaps *merge* the tables together or is this OK?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
